apiVersion: apps/v1
kind: Deployment
metadata:
  name: unimodel
  namespace: unimodel
  labels:
    app: unimodel
    version: v1.0.0
spec:
  replicas: 3
  selector:
    matchLabels:
      app: unimodel
  template:
    metadata:
      labels:
        app: unimodel
        version: v1.0.0
    spec:
      containers:
        - name: unimodel
          image: unimodel:latest
          ports:
            - containerPort: 8000
              name: http
            - containerPort: 9000
              name: grpc
            - containerPort: 9090
              name: metrics
          env:
            - name: RUST_LOG
              value: "info"
            - name: UNIMODEL_HOST
              value: "0.0.0.0"
            - name: UNIMODEL_PORT
              value: "8000"
            - name: UNIMODEL_GRPC_PORT
              value: "9000"
            - name: UNIMODEL_GPU_DEVICES
              value: "0"
          resources:
            requests:
              memory: "2Gi"
              cpu: "1000m"
              nvidia.com/gpu: 1
            limits:
              memory: "8Gi"
              cpu: "4000m"
              nvidia.com/gpu: 1
          volumeMounts:
            - name: config
              mountPath: /app/config
            - name: models
              mountPath: /app/models
            - name: cache
              mountPath: /app/cache
            - name: logs
              mountPath: /app/logs
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /ready
              port: 8000
            initialDelaySeconds: 5
            periodSeconds: 5
      volumes:
        - name: config
          configMap:
            name: unimodel-config
        - name: models
          persistentVolumeClaim:
            claimName: unimodel-models
        - name: cache
          persistentVolumeClaim:
            claimName: unimodel-cache
        - name: logs
          persistentVolumeClaim:
            claimName: unimodel-logs
      nodeSelector:
        accelerator: nvidia-tesla-v100
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule

---
apiVersion: v1
kind: Service
metadata:
  name: unimodel-service
  namespace: unimodel
  labels:
    app: unimodel
spec:
  selector:
    app: unimodel
  ports:
    - port: 8000
      targetPort: 8000
      name: http
    - port: 9000
      targetPort: 9000
      name: grpc
    - port: 9090
      targetPort: 9090
      name: metrics
  type: LoadBalancer

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: unimodel-config
  namespace: unimodel
data:
  production.yaml: |
    server:
      host: "0.0.0.0"
      port: 8000
      grpc_port: 9000
      max_connections: 1000
      request_timeout_secs: 300
      enable_tls: false
      worker_threads: 4

    engine:
      max_models: 10
      default_batch_size: 16
      max_batch_wait_ms: 50
      batch_config:
        max_batch_size: 32
        max_wait_time_ms: 100
        timeout_ms: 30000
      gpu:
        device_ids: [0]
        memory_fraction: 0.8
        enable_pooling: true
      memory:
        max_memory_gb: 32.0
        enable_mmap: true
        cache_size_mb: 4096

    plugins:
      plugin_dir: "/app/plugins"
      enabled_plugins:
        - "pytorch"
        - "onnx"
        - "tensorrt"
      plugin_timeout_secs: 300

    monitoring:
      prometheus_enabled: true
      prometheus_port: 9090
      jaeger_enabled: true
      jaeger_endpoint: "http://jaeger-collector:14268"
      health_check_interval_secs: 30
      metrics_collection_interval_secs: 60

    security:
      auth_enabled: true
      cors_enabled: true
      cors_allowed_origins: ["*"]
      rate_limiting:
        enabled: true
        requests_per_minute: 10000
        burst_size: 1000

    storage:
      model_storage_path: "/app/models"
      cache_storage_path: "/app/cache"
      log_storage_path: "/app/logs"
      max_storage_gb: 1000

    logging:
      level: "info"
      format: "json"
      console_output: true
      file_output: true
      file_path: "/app/logs/unimodel.log"
      rotation_size_mb: 100
      retention_count: 10

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: unimodel-models
  namespace: unimodel
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 500Gi
  storageClassName: fast-ssd

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: unimodel-cache
  namespace: unimodel
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 100Gi
  storageClassName: fast-ssd

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: unimodel-logs
  namespace: unimodel
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 50Gi
  storageClassName: standard